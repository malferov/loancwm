{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give\n",
      "False     265\n",
      "True     4233\n",
      "Name: give, dtype: int64\n",
      "0.93739664540515\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4498 entries, 0 to 4586\n",
      "Data columns (total 53 columns):\n",
      "tender_num                        4498 non-null int64\n",
      "deal_date                         4498 non-null datetime64[ns]\n",
      "report_date                       4498 non-null datetime64[ns]\n",
      "period                            4498 non-null int64\n",
      "credit_amount                     4498 non-null float64\n",
      "return_amount                     4498 non-null float64\n",
      "rate                              4498 non-null float64\n",
      "outstanding                       4498 non-null float64\n",
      "return_date                       4498 non-null datetime64[ns]\n",
      "expiration_date                   4498 non-null datetime64[ns]\n",
      "tender_credit_amount              4498 non-null float64\n",
      "tender_return_amount              4498 non-null float64\n",
      "tender_interest_rate              4498 non-null float64\n",
      "credit_amount_average             4498 non-null float64\n",
      "credit_amount_to_average_ratio    4498 non-null float64\n",
      "average_repeated_loan_count       4498 non-null float64\n",
      "creditors_count                   4498 non-null int64\n",
      "delinq                            4498 non-null int64\n",
      "rating                            4498 non-null float64\n",
      "business_level                    4498 non-null int64\n",
      "debt                              4498 non-null float64\n",
      "return_rate                       4498 non-null float64\n",
      "return_amount_rate                4498 non-null float64\n",
      "credit_amount_total               4498 non-null float64\n",
      "credit_count_total                4498 non-null float64\n",
      "model                             4498 non-null object\n",
      "reg_country_id                    4498 non-null int64\n",
      "reg_country                       4498 non-null object\n",
      "reg_city                          4498 non-null object\n",
      "pass_date                         4498 non-null datetime64[ns]\n",
      "purpose                           4498 non-null object\n",
      "guarantee                         4498 non-null object\n",
      "address                           4498 non-null object\n",
      "recommend                         4498 non-null object\n",
      "wmid                              4498 non-null object\n",
      "loan_count                        4498 non-null int64\n",
      "loan_count_total                  4498 non-null int64\n",
      "reg_city_code                     4498 non-null int64\n",
      "empty_info                        4498 non-null int64\n",
      "purpose_category                  4498 non-null object\n",
      "purpose_code                      4498 non-null int64\n",
      "deal_date_year                    4498 non-null int64\n",
      "deal_date_month                   4498 non-null int64\n",
      "return_date_year                  4498 non-null int64\n",
      "return_date_month                 4498 non-null int64\n",
      "expiration_date_year              4498 non-null int64\n",
      "expiration_date_month             4498 non-null int64\n",
      "report_date_year                  4498 non-null int64\n",
      "report_date_month                 4498 non-null int64\n",
      "pass_date_year                    4498 non-null int64\n",
      "pass_date_month                   4498 non-null int64\n",
      "score                             4498 non-null float64\n",
      "give                              4498 non-null bool\n",
      "dtypes: bool(1), datetime64[ns](5), float64(17), int64(21), object(9)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "%run Data\\ load.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit, KFold, cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, r2_score, explained_variance_score, mean_squared_error, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'deal_date_month',\n",
    "    'expiration_date_month',\n",
    "    'period',\n",
    "    'credit_amount',\n",
    "    'credit_amount_total',\n",
    "    'creditors_count',\n",
    "    'purpose_code',\n",
    "    'rate',\n",
    "#    'debt',\n",
    "    'loan_count',\n",
    "    'business_level',\n",
    "    'reg_country_id',\n",
    "    'reg_city_code',\n",
    "    'pass_date_year',\n",
    "    'empty_info',\n",
    "    'return_rate',\n",
    "    'return_amount_rate',\n",
    "    'tender_interest_rate',\n",
    "    'tender_credit_amount',\n",
    "    'credit_amount_average',\n",
    "    'credit_amount_to_average_ratio',\n",
    "    'average_repeated_loan_count',\n",
    "#    'connotation'\n",
    "]\n",
    "#deals[['credit_amount_total','return_rate', 'return_amount_rate']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des predictor sur le train set :  (3373, 21)\n",
      "Taille de la target sur le train set :  (3373,)\n",
      "Taille des predictor sur le test set :  (1125, 21)\n",
      "Taille de la target sur le test set :  (1125,)\n"
     ]
    }
   ],
   "source": [
    "y = deals['give']\n",
    "X = deals[features]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X.values, y.values, test_size=0.25)\n",
    "print(\"Taille des predictor sur le train set : \", train_X.shape)\n",
    "print(\"Taille de la target sur le train set : \", train_y.shape)\n",
    "print(\"Taille des predictor sur le test set : \", test_X.shape)\n",
    "print(\"Taille de la target sur le test set : \", test_y.shape)\n",
    "\n",
    "counts = deals.groupby('give')['give'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sur le train :  0.8982679962198977\n",
      "Performance sur le test :  0.7685646829165349\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "my_model = XGBRegressor(n_estimators=1000)\n",
    "my_model.fit(train_X, train_y, early_stopping_rounds=2, \n",
    "             eval_set=[(test_X, test_y)], verbose=False)\n",
    "\n",
    "train_y_pred = my_model.predict(train_X)\n",
    "auc = roc_auc_score(train_y, train_y_pred)\n",
    "print(\"Performance sur le train : \", auc)\n",
    "\n",
    "test_y_pred = my_model.predict(test_X)\n",
    "auc = roc_auc_score(test_y, test_y_pred)\n",
    "print(\"Performance sur le test : \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sur le train :  0.9995283018867924\n",
      "Performance sur le test :  0.6085588793922128\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.1, n_estimators=1000,\n",
    "    max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27)\n",
    "\n",
    "xgb1.fit(train_X, train_y)\n",
    "\n",
    "auc = roc_auc_score(train_y, xgb1.predict(train_X))\n",
    "print(\"Performance sur le train : \", auc)\n",
    "\n",
    "auc = roc_auc_score(test_y, xgb1.predict(test_X))\n",
    "print(\"Performance sur le test : \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'min_child_weight': 3}, 0.748077347456692)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1000, \n",
    "                                                  max_depth=5,\n",
    "                                                  min_child_weight=1,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective='binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27), \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch1.fit(train_X,train_y)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sur le train :  0.9883647798742139\n",
      "Performance sur le test :  0.6163936372269705\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    "    learning_rate=0.1, n_estimators=1000,\n",
    "    gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27,\n",
    "    max_depth = 3,\n",
    "    min_child_weight = 3\n",
    ")\n",
    "\n",
    "xgb2.fit(train_X, train_y)\n",
    "\n",
    "auc = roc_auc_score(train_y, xgb2.predict(train_X))\n",
    "print(\"Performance sur le train : \", auc)\n",
    "\n",
    "auc = roc_auc_score(test_y, xgb2.predict(test_X))\n",
    "print(\"Performance sur le test : \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'gamma': 0.4}, 0.7590554155102318)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = { \n",
    "    'gamma':[i/10.0 for i in range(0,5)] \n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "                                                  n_estimators=1000, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=3,\n",
    "                                                  gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                  objective='binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27), \n",
    "                        param_grid = param_test3, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch3.fit(train_X,train_y)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sur le train :  0.9765723270440252\n",
      "Performance sur le test :  0.625534188034188\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    "    learning_rate=0.1, \n",
    "    n_estimators=1000,\n",
    "    gamma=0.4,\n",
    "    subsample=0.8, colsample_bytree=0.8,\n",
    "    objective='binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27,\n",
    "    max_depth=3,\n",
    "    min_child_weight=3\n",
    ")\n",
    "\n",
    "xgb3.fit(train_X, train_y)\n",
    "\n",
    "auc = roc_auc_score(train_y, xgb3.predict(train_X))\n",
    "print(\"Performance sur le train : \", auc)\n",
    "\n",
    "auc = roc_auc_score(test_y, xgb3.predict(test_X))\n",
    "print(\"Performance sur le test : \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.8, 'subsample': 0.8}, 0.7590554155102318)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=1000, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=3,\n",
    "                                                  gamma=0.4, \n",
    "                                                  subsample=0.8, colsample_bytree=0.8,\n",
    "                                                  objective='binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27), \n",
    "                        param_grid = param_test4, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch4.fit(train_X, train_y)\n",
    "gsearch4.best_params_, gsearch4.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sur le train :  0.9765723270440252\n",
      "Performance sur le test :  0.625534188034188\n"
     ]
    }
   ],
   "source": [
    "xgb5 = XGBClassifier(\n",
    "    learning_rate=0.1, \n",
    "    n_estimators=1000,\n",
    "    gamma=0.4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    max_depth=3,\n",
    "    min_child_weight=3,\n",
    "    objective='binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27\n",
    ")\n",
    "\n",
    "xgb5.fit(train_X, train_y)\n",
    "\n",
    "auc = roc_auc_score(train_y, xgb5.predict(train_X))\n",
    "print(\"Performance sur le train : \", auc)\n",
    "\n",
    "auc = roc_auc_score(test_y, xgb5.predict(test_X))\n",
    "print(\"Performance sur le test : \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.009}, 0.7722370755141361)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'learning_rate':[i/1000.0 for i in range(5,20,2)]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, \n",
    "                                                  n_estimators=1000, \n",
    "                                                  gamma=0.4,\n",
    "                                                  subsample=0.8,\n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=3,\n",
    "                                                  objective= 'binary:logistic', nthread=4, scale_pos_weight=counts[0]/counts[1], seed=27), \n",
    "                        param_grid = param_test6, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch6.fit(train_X, train_y)\n",
    "gsearch6.best_params_, gsearch6.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance sur le train :  0.8711278391501287\n",
      "Performance sur le test :  0.6692188983855651\n"
     ]
    }
   ],
   "source": [
    "xgb6 = XGBClassifier(\n",
    "    learning_rate=0.009,\n",
    "    n_estimators=1000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.005,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=counts[0]/counts[1],\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "xgb6.fit(train_X, train_y)\n",
    "\n",
    "auc = roc_auc_score(train_y, xgb6.predict(train_X))\n",
    "print(\"Performance sur le train : \", auc)\n",
    "\n",
    "auc = roc_auc_score(test_y, xgb6.predict(test_X))\n",
    "print(\"Performance sur le test : \", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate  :  0.16958197450340942\n",
      "Accuracy  :  0.8304180254965906\n",
      "Sensitivity  :  0.8251572327044026\n",
      "Specificity  :  0.8251572327044026\n",
      "False positive rate  :  0.08290155440414508\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_y, xgb6.predict(train_X)).ravel()\n",
    "# Error rate : \n",
    "err_rate = (fp + fn) / (tp + tn + fn + fp)\n",
    "print(\"Error rate  : \", err_rate)\n",
    "# Accuracy : \n",
    "acc_ = (tp + tn) / (tp + tn + fn + fp)\n",
    "print(\"Accuracy  : \", acc_)\n",
    "# Sensitivity : \n",
    "sens_ = tp / (tp + fn)\n",
    "print(\"Sensitivity  : \", sens_)\n",
    "# Specificity \n",
    "sp_ = tn / (tn + fp)\n",
    "print(\"Specificity  : \", sens_)\n",
    "# False positive rate (FPR)\n",
    "FPR = fp / (tn + fp)\n",
    "print(\"False positive rate  : \", FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate  on train set :  0.16958197450340942\n",
      "Accuracy  on train set  :  0.8304180254965906\n",
      "Error rate  on test set :  0.21955555555555556\n",
      "Accuracy  on test set  :  0.7804444444444445\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(train_y, xgb6.predict(train_X)).ravel()\n",
    "# Error rate : \n",
    "err_rate = (fp + fn) / (tp + tn + fn + fp)\n",
    "print(\"Error rate  on train set : \", err_rate)\n",
    "# Accuracy : \n",
    "acc_ = (tp + tn) / (tp + tn + fn + fp)\n",
    "print(\"Accuracy  on train set  : \", acc_)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, xgb6.predict(test_X)).ravel()\n",
    "# Error rate : \n",
    "err_rate = (fp + fn) / (tp + tn + fn + fp)\n",
    "print(\"Error rate  on test set : \", err_rate)\n",
    "# Accuracy : \n",
    "acc_ = (tp + tn) / (tp + tn + fn + fp)\n",
    "print(\"Accuracy  on test set  : \", acc_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
